"use strict";(self.webpackChunkegoexo_docs=self.webpackChunkegoexo_docs||[]).push([[2881],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>k});var i=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var p=i.createContext({}),l=function(e){var t=i.useContext(p),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=l(e.components);return i.createElement(p.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},u=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,p=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),d=l(n),u=a,k=d["".concat(p,".").concat(u)]||d[u]||m[u]||r;return n?i.createElement(k,o(o({ref:t},c),{},{components:n})):i.createElement(k,o({ref:t},c))}));function k(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,o=new Array(r);o[0]=u;var s={};for(var p in t)hasOwnProperty.call(t,p)&&(s[p]=t[p]);s.originalType=e,s[d]="string"==typeof e?e:a,o[1]=s;for(var l=2;l<r;l++)o[l]=n[l];return i.createElement.apply(null,o)}return i.createElement.apply(null,n)}u.displayName="MDXCreateElement"},3103:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>o,default:()=>m,frontMatter:()=>r,metadata:()=>s,toc:()=>l});var i=n(7462),a=(n(7294),n(3905));const r={title:"Fine-grained Keystep Recognition",sidebar_position:1},o=void 0,s={unversionedId:"benchmarks/keystep/keystep_recoginition",id:"benchmarks/keystep/keystep_recoginition",title:"Fine-grained Keystep Recognition",description:"Predict the keystep for a given video clip (trimmed by time).",source:"@site/docs/benchmarks/keystep/keystep_recoginition.md",sourceDirName:"benchmarks/keystep",slug:"/benchmarks/keystep/keystep_recoginition",permalink:"/benchmarks/keystep/keystep_recoginition",draft:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{title:"Fine-grained Keystep Recognition",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Keystep",permalink:"/benchmarks/keystep/"},next:{title:"Task Graph",permalink:"/benchmarks/keystep/task_graph"}},p={},l=[{value:"Task definition",id:"task-definition",level:3},{value:"Data",id:"data",level:3},{value:"Annotations",id:"annotations",level:3},{value:"JSON file format",id:"json-file-format",level:4},{value:"Label mapping file",id:"label-mapping-file",level:4},{value:"Metrics",id:"metrics",level:3},{value:"Baselines",id:"baselines",level:3}],c={toc:l},d="wrapper";function m(e){let{components:t,...n}=e;return(0,a.kt)(d,(0,i.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,"Predict the keystep for a given video clip (trimmed by time)."),(0,a.kt)("h3",{id:"task-definition"},"Task definition"),(0,a.kt)("p",null,"This task involves recognizing fine-grained keysteps from procedural egocentric videos (at test time), using models that can leverage multiple, time-synchronized views (at training time)."),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Train instance:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"- 1 ego + N exo trimmed video clips\n- Keystep label\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"Test instance:")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"Input: A trimmed egocentric video clip\nOutput: Predicted keystep label\n")),(0,a.kt)("p",null,"Note that at test time, the input to the model includes just the ego-view videos (RGB only). Exo-view videos, activity and scenario names, narrations, audio and associated metadata such as eye gaze, 3D point\nclouds, camera pose, and IMU information are excluded as inputs for inference (although we encourage exploring their potential utility in training) as our ultimate goal is a vision-centric approach that performs egocentric keystep recognition."),(0,a.kt)("h3",{id:"data"},"Data"),(0,a.kt)("p",null,"To download the preprocessed keystep segments, use the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"egoexo -o <out-dir> --parts keystep_benchmark/clips_448p\n")),(0,a.kt)("h3",{id:"annotations"},"Annotations"),(0,a.kt)("p",null,"You can download the annotations using ",(0,a.kt)("inlineCode",{parentName:"p"},"--parts annotations")," and optionally include ",(0,a.kt)("inlineCode",{parentName:"p"},"--benchmarks keystep"),". The structure of the annotation files for the keystep benchmark is as follows:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"\u251c\u2500\u2500 keystep_benchmark\n\u2502   \u251c\u2500\u2500 keystep_segment_test_unannotated.json\n\u2502   \u251c\u2500\u2500 keystep_segment_train.json\n\u2502   \u251c\u2500\u2500 keystep_segment_val.json\n\u2502   \u2514\u2500\u2500 label_mapping.csv\n")),(0,a.kt)("h4",{id:"json-file-format"},"JSON file format"),(0,a.kt)("p",null,"The three JSON files (",(0,a.kt)("inlineCode",{parentName:"p"},"keystep_segment_train.json"),", ",(0,a.kt)("inlineCode",{parentName:"p"},"keystep_segment_val.json"),",\nand ",(0,a.kt)("inlineCode",{parentName:"p"},"keystep_segment_test_unannotated.json"),") are generated from keystep\nannotations. Each ",(0,a.kt)("inlineCode",{parentName:"p"},"segment_name")," corresponds to the names of the ",(0,a.kt)("a",{parentName:"p",href:"#data"},"preprocessed\nkeysteps"),"."),(0,a.kt)("p",null,"Sample JSON:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'{\n    "date": "04/02/2024",\n    "description": "EgoExo4D Fine-grained Keystep Recognition",\n    "splits": "train",\n    "segments": [\n        {\n            "segment_name_list": [\n                "train/georgiatech_covid_07_6/start0.85598_end33.20377_aria02_214-1.mp4",\n                "train/georgiatech_covid_07_6/start0.85598_end33.20377_cam01.mp4",\n                "train/georgiatech_covid_07_6/start0.85598_end33.20377_cam02.mp4",\n                "train/georgiatech_covid_07_6/start0.85598_end33.20377_cam03.mp4",\n                "train/georgiatech_covid_07_6/start0.85598_end33.20377_cam04.mp4"\n            ],\n            "ego_segment_name": "train/georgiatech_covid_07_6/start0.85598_end33.20377_aria02_214-1.mp4",\n            "take_uid": "77cd56fc-6b68-4c7f-814b-81545484dd2d",\n            "take_name": "georgiatech_covid_07_6",\n            "start_time": 0.85598,\n            "end_time": 33.20377,\n            "step_unique_id": 843,\n            "label_id": 35,\n            "step_name": "Unbox package"\n        },\n    ...\n    ]\n}\n')),(0,a.kt)("h4",{id:"label-mapping-file"},"Label mapping file"),(0,a.kt)("p",null,"The 278 keysteps used in the benchmark are derived from the original keystep annotations with a cutoff threshold of 20. The mapping is provided in ",(0,a.kt)("inlineCode",{parentName:"p"},"label_mapping.csv"),"."),(0,a.kt)("p",null,"Sample CSV:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"label_id,step_unique_id,step_name,scenario_name\n0,1567,Stir the mixture,cooking\n1,502,Check paper recipe,cooking\n2,492,Adjust the stove heat,cooking\n...\n")),(0,a.kt)("h3",{id:"metrics"},"Metrics"),(0,a.kt)("p",null,"We measure top-1 keystep recognition accuracy (%)"),(0,a.kt)("h3",{id:"baselines"},"Baselines"),(0,a.kt)("p",null,"Baseline repo: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/EGO4D/ego-exo4d-keystep/tree/main/fine_grained"},"https://github.com/EGO4D/ego-exo4d-keystep/tree/main/fine_grained")))}m.isMDXComponent=!0}}]);